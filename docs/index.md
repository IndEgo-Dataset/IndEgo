# IndEgo: Industrial Egocentric Assistant

## Industrial Automation and Robotics | Augmenting Human Skills with AI!

Welcome to the IndEgo project â€” an open-source framework for building AI-powered assistants that learn from skilled workers in industrial environments.  
ðŸ‘‰ [GitHub Repo](https://github.com/Vivek9Chavan/IndEgo)

<p align="left">
  <img src="https://github.com/user-attachments/assets/fcf2e236-768a-4348-9762-28f4fa62d405" alt="IndEgo Logo" width="500"/>
</p>

---

## About

**IndEgo** combines Egocentric AI, Vision-Language Models, and Robotics-aware reasoning to understand human actions and provide real-time guidance. It is designed for use in industrial settings through smart glasses or mobile devices â€” enabling contextual assistance, task verification, and human-robot collaboration.

IndEgo supports use cases such as:
- Industrial task training and onboarding  
- Real-time guidance and error prevention  
- Knowledge transfer from experts to new operators  
- AI-augmented collaboration between workers and machines  

Built as a privacy-first, open-source project, IndEgo gives organizations full control over data, deployment, and customization.

---

## Technology

IndEgo runs on an adaptable framework that leverages:
- **Egocentric computer vision** for task context understanding  
- **Vision-language models (VLMs)** for multi-modal reasoning and interaction  
- **Robotics-aware logic** to align human guidance with automated systems  
- **Smart glasses or mobile devices** for real-time, on-site use  

---

## Features

- ðŸ§  Learns from expert demonstrations  
- ðŸ“± Works with smart glasses or mobile devices  
- ðŸ› ï¸ Customizable and extensible for various industrial domains  
- ðŸ” Privacy-preserving â€” no cloud upload required  
- ðŸ¤– Compatible with robotics workflows and task handoffs

---

## Demo

> ðŸŽ¥ Below is a demo of IndEgo in action (auto-play + loop):

<video width="100%" autoplay loop muted playsinline>
  <source src="https://drive.google.com/uc?export=preview&id=1x1TnZJpUdE2BDMW9H-jo3QZmdm-aGrZb" type="video/mp4">
  Your browser does not support the video tag.
</video>

---

## Try It â€“ No Setup Required!

ðŸ‘‰ [Launch Colab Notebook](https://colab.research.google.com/drive/1mC-W5czouMFgICMktrffOU7sSjMBXENO?usp=sharing)  
Run IndEgo's core logic directly in your browser using Google Colab â€” no install or setup needed.

---

## Dataset

ðŸ”— [Open-source Dataset on Hugging Face](https://huggingface.co/datasets/vivek9chavan/IndEgo_Demo)  
The IndEgo demo dataset includes annotated egocentric videos from real-world industrial tasks, ready for VLM, task graph, and mistake detection research.

---

## Get Involved

We are currently looking for:
- **Industry partners** to run pilot studies and co-develop real-world applications  
- **Research collaborators** to explore multi-modal AI, robotics, and egocentric vision  
- **Developers and contributors** to extend the IndEgo framework  

ðŸ’¬ Interested? Reach out or visit us at our [GITEX Europe showcase â€“ Hall 4.2](https://www.gitex-europe.com/)

---

## License

MIT License â€“ see the [GitHub repo](https://github.com/Vivek9Chavan/IndEgo) for details.
